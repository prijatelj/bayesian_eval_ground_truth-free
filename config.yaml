# Configuration file for running the tests. This will be assumed defaults,
# passed arguements to scripts will replace the value for that specific run of
# that script.
# So the order of precedence:
# specified arguments script calls > config values > script defaults (if any).
# Not all values are used here by the scripts.

# Hardware constants
#cores: 1 # If empty/null/None the maximum number of cores available will be used
#threads: lol this is Python.

# Random Seeds file
random_seeds_file:  'random_seeds_count-10000.txt'

output_dir: 'results/'


# Predictive Models evaluation variables.
n_nested_loop_count: 10
k_folds: 10

# Annotated datasets to be used, and their respective predictive models
# If any dataset is not a string, but a dict, then that dict may contain the
# filepath to the dataset rather than the default expected filepath.
datasets:
    # Truth Inference Sruvey 2017
    - d_Duck Idnetification
    - d_jn-product
    - d_sentiment
    - s4_Dog data
    - s4_Face Sentiment Identification
    - s4_Relevance
    - s5_AdultContent
    - f201_Emotion_FULL

    # Comparison of Bayesian Models of Annotation 2018
    # Snow 2008:
    - anger
    - disgust
    - fear
    - joy
    - rte
    - sadness
    - surprise
    - temp
    - valence
    - wordsim
    #- wsd # a mapping problem no TI method can handle.

    # CrowdLayer
    - LabelMe
    - MovieReviews
    - ner_mturk

    # Ipeirotis datasets
    - AdultContent
    - AdultContent2
    - AdultContent3
    - BarzanMozafari
    - CopyrightInfringement
    - HITspam-UsingCrowdFlower
    - HITspam-UsingMTurk
    - JeroenVurrens

    # TREC Relevancy 2010
    - trec_relevancy_2010

    # Computer Vision datasets
    # facial_beauty
    - All_Ratings
    - Asian_Females
    - Asian_Males
    - Caucasian_Females
    - Caucasian_Males

    # first impressions
    - age
    - dominance
    - iq
    - trustworthiness

    # Volcano dataset
    - volcano

# Truth inference models to be tested
truth_inference:
    models:
        # An Evaluation of Aggregation Techniques in Crowdsourcing
        # non-probabilistic
        majority_vote: None
        mean: None
        median: None
        majority_decision: None
        honypot: None
        ELICE: None
        # probablistic
        ipeirotis_dawid_skene: None
        SLME: None
        ITER: None

        # Comparison of Bayesian Models of Annotation 2018
        multinomial: None
        # dawid_skene : max_iterations, prior
        dawid_skene:
            # using the values given via TI survey script.
            max_iterations: 20
            prior_quality: 0.7
        hier_dawid_skene: None
        item_diff: None
        log_rnd_eff: None
        MACE: None

        # Truth Inference Survey 2017 (those not included above)
        ZenCrowd: None
        GLAD: None
        minimax: None
        BCC: None
        CBCC: None
        LFC: None
        LFC-N: None
        CATD: None
        PM: None
        Multi: None
        KOS: None
        VI-BP: None
        VI-MF: None

        # Multi-Class Ground Truth Inference in Crowdsourcing with Clustering 2016
        spectral_dawid_skene: None
        # Ground Truth Inference using Clustering
        GTIC: None

# Metrics to be tested and used in evaluating models
metrics:
    any:
        - wasserstein_distance # Earth Mover's Distance
    regression:
        - MAE
        - RMSE
    classification:
        - accuracy
        - f1_score
        - confusion_matrix
