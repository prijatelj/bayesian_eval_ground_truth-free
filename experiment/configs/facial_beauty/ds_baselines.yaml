# Configuration file for running the tests. This will be assumed defaults,
# passed arguements to scripts will replace the value for that specific run of
# that script.
# So the order of precedence:
# specified arguments script calls > config values > script defaults (if any).
# Not all values are used here by the scripts.

# Hardware constants
#cores: 1 # If empty/null/None the maximum number of cores available will be used
#threads: lol this is Python.

# Random Seeds file
random_seeds_file:  'experiment/random_seeds/random_seeds_count-10000.txt'

output_dir: 'results/'

# Annotated datasets to be used, and their respective predictive models
# If any dataset is not a string, but a dict, then that dict may contain the
# filepath to the dataset rather than the default expected filepath.
datasets:
    # Computer Vision datasets
    # facial_beauty
    - All_Ratings
    - Asian_Female
    - Asian_Male
    - Caucasian_Female
    - Caucasian_Male

# Truth inference models to be tested
truth_inference:
    models:
        # Baselines:
        # regression
        mean: None
        median: None
        mode: None

        # classification
        majority_vote: None
        frequency: None
        count_occurences: None

        # Comparison of Bayesian Models of Annotation 2018
        # dawid_skene : max_iterations, prior
        dawid_skene:
            # using the values given via TI survey script.
            max_iterations: 20
            prior_quality: 0.7
